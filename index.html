<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Oylwhu Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Oylwhu Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Oylwhu Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Oylwhu Blog">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="Oylwhu Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://7xract.com1.z0.glb.clouddn.com/favicon.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Oylwhu Blog</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/oylwhu" title="github">github</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a> <a href="/tags/network/" style="font-size: 15px;">network</a> <a href="/tags/学习笔记/" style="font-size: 20px;">学习笔记</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">短暂年华，绚丽人生。用那个青春的热血点燃未来的希望，让人生的每一个角落都色彩飞扬。让那犹如白纸的未来色彩斑斓，不再单调，让我们的人生像一部电影不断演绎精彩的每一个片段。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Oylwhu Blog</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://7xract.com1.z0.glb.clouddn.com/favicon.png" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Oylwhu Blog</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/oylwhu" title="github">github</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-MapReduce框架详解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/10/03/MapReduce框架详解/" class="article-date">
  	<time datetime="2015-10-03T11:33:02.000Z" itemprop="datePublished">2015-10-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/10/03/MapReduce框架详解/">MapReduce框架详解</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="MapReduce_u6846_u67B6_u8BE6_u89E3"><a href="#MapReduce_u6846_u67B6_u8BE6_u89E3" class="headerlink" title="MapReduce框架详解"></a>MapReduce框架详解</h2><blockquote>
<p>我现在学习技术很喜欢看图，每次有了新理解就会去看看图，每次都会有新的发现。<br>谈mapreduce运行机制，可以从很多不同的角度来描述，比如说从mapreduce运行流程来讲解，也可以从计算模型的逻辑流程来进行讲解，也许有些深入理解了mapreduce运行机制还会从更好的角度来描述，但是将mapreduce运行机制有些东西是避免不了的，就是一个个参入的实例对象，一个就是计算模型的逻辑定义阶段，我这里讲解不从什么流程出发，就从这些一个个牵涉的对象，不管是物理实体还是逻辑实体。<br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Kuangjia1.jpg" alt="MapReduce1"><br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Kuangjia2.jpg" alt="MapReduce2"><br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Kuangjia3.jpg" alt="MapReduce3"><br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Kuangjia4.jpg" alt="MapReduce4"><br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Kuangjia5.jpg" alt="MapReduce5"><br>下面介绍MapReduce的部分参数及其默认设置：<br>（1）InputFormat类<br>该类的作用是将输入的数据分割成一个个的split，并将split进一步拆分成<key, value="">对作为map函数的输入<br>（2）Mapper类<br>实现map函数，根据输入的<key, value="">对生产中间结果<br>（3）Combiner<br>实现combine函数，合并中间结果中具有相同key值的键值对。<br>（4）Partitioner类<br>实现getPartition函数，用于在Shuffle过程按照key值将中间数据分成R份，每一份由一个Reduce负责<br>（5）Reducer类<br>实现reduce函数，将中间结果合并，得到最终的结果<br>（6）OutputFormat类<br>该类负责输出最终的结果<br>首先讲讲物理实体，参入mapreduce作业执行涉及4个独立的实体：<br>（1）客户端（client）：编写mapreduce程序，配置作业，提交作业，这就是程序员完成的工作；<br>（2）JobTracker：初始化作业，分配作业，与TaskTracker通信，协调整个作业的执行；<br>（3）TaskTracker：保持与JobTracker的通信，在分配的数据片段上执行Map或Reduce任务，TaskTracker和JobTracker的不同有个很重要的方面，就是在执行任务时候TaskTracker可以有n多个，JobTracker则只会有一个（JobTracker只能有一个就和hdfs里namenode一样存在单点故障，我会在后面的mapreduce的相关问题里讲到这个问题的）<br>（4）Hdfs：保存作业的数据、配置信息等等，最后的结果也是保存在hdfs上面<br>那么mapreduce到底是如何运行的呢？<br>首先是客户端要编写好mapreduce程序，配置好mapreduce的作业也就是job，接下来就是提交job了，提交job是提交到JobTracker上的，这个时候JobTracker就会构建这个job，具体就是分配一个新的job任务的ID值，接下来它会做检查操作，这个检查就是确定输出目录是否存在，如果存在那么job就不能正常运行下去，JobTracker会抛出错误给客户端，接下来还要检查输入目录是否存在，如果不存在同样抛出错误，如果存在JobTracker会根据输入计算输入分片（Input Split），如果分片计算不出来也会抛出错误，至于输入分片我后面会做讲解的，这些都做好了JobTracker就会配置Job需要的资源了。分配好资源后，JobTracker就会初始化作业，初始化主要做的是将Job放入一个内部的队列，让配置好的作业调度器能调度到这个作业，作业调度器会初始化这个job，初始化就是创建一个正在运行的job对象（封装任务和记录信息），以便JobTracker跟踪job的状态和进程。<br>初始化完毕后，作业调度器会获取输入分片信息（input split），每个分片创建一个map任务。接下来就是任务分配了，这个时候tasktracker会运行一个简单的循环机制定期发送心跳给jobtracker，心跳间隔是5秒，程序员可以配置这个时间，心跳就是jobtracker和tasktracker沟通的桥梁，通过心跳，jobtracker可以监控tasktracker是否存活，也可以获取tasktracker处理的状态和问题，同时tasktracker也可以通过心跳里的返回值获取jobtracker给它的操作指令。任务分配好后就是执行任务了。在任务执行时候jobtracker可以通过心跳机制监控tasktracker的状态和进度，同时也能计算出整个job的状态和进度，而tasktracker也可以本地监控自己的状态和进度。当jobtracker获得了最后一个完成指定任务的tasktracker操作成功的通知时候，jobtracker会把整个job状态置为成功，然后当客户端查询job运行状态时候（注意：这个是异步操作），客户端会查到job完成的通知的。如果job中途失败，mapreduce也会有相应机制处理，一般而言如果不是程序员程序本身有bug，mapreduce错误处理机制都能保证提交的job能正常完成。</key,></key,></p>
</blockquote>
<hr>
<blockquote>
<p>下面我从逻辑实体的角度讲解mapreduce运行机制，这些按照时间顺序包括：输入分片（input split）、map阶段、combiner阶段、shuffle阶段和reduce阶段。<br>（1）. 输入分片（input split）：在进行map计算之前，mapreduce会根据输入文件计算输入分片（input split），每个输入分片（input split）针对一个map任务，输入分片（input split）存储的并非数据本身，而是一个分片长度和一个记录数据的位置的数组，输入分片（input split）往往和hdfs的block（块）关系很密切，假如我们设定hdfs的块的大小是64mb，如果我们输入有三个文件，大小分别是3mb、65mb和127mb，那么mapreduce会把3mb文件分为一个输入分片（input split），65mb则是两个输入分片（input split）而127mb也是两个输入分片（input split），换句话说我们如果在map计算前做输入分片调整，例如合并小文件，那么就会有5个map任务将执行，而且每个map执行的数据大小不均，这个也是mapreduce优化计算的一个关键点。</p>
<ol>
<li>map阶段：就是程序员编写好的map函数了，因此map函数效率相对好控制，而且一般map操作都是本地化操作也就是在数据存储节点上进行；</li>
<li>combiner阶段：combiner阶段是程序员可以选择的，combiner其实也是一种reduce操作，因此我们看见WordCount类里是用reduce进行加载的。Combiner是一个本地化的reduce操作，它是map运算的后续操作，主要是在map计算出中间文件前做一个简单的合并重复key值的操作，例如我们对文件里的单词频率做统计，map计算时候如果碰到一个hadoop的单词就会记录为1，但是这篇文章里hadoop可能会出现n多次，那么map输出文件冗余就会很多，因此在reduce计算前对相同的key做一个合并操作，那么文件会变小，这样就提高了宽带的传输效率，毕竟hadoop计算力宽带资源往往是计算的瓶颈也是最为宝贵的资源，但是combiner操作是有风险的，使用它的原则是combiner的输入不会影响到reduce计算的最终输入，例如：如果计算只是求总数，最大值，最小值可以使用combiner，但是做平均值计算使用combiner的话，最终的reduce计算结果就会出错。</li>
<li>shuffle阶段：将map的输出作为reduce的输入的过程就是shuffle了，这个是mapreduce优化的重点地方。这里我不讲怎么优化shuffle阶段，讲讲shuffle阶段的原理，因为大部分的书籍里都没讲清楚shuffle阶段。Shuffle一开始就是map阶段做输出操作，一般mapreduce计算的都是海量数据，map输出时候不可能把所有文件都放到内存操作，因此map写入磁盘的过程十分的复杂，更何况map输出时候要对结果进行排序，内存开销是很大的，map在做输出时候会在内存里开启一个环形内存缓冲区，这个缓冲区专门用来输出的，默认大小是100mb，并且在配置文件里为这个缓冲区设定了一个阀值，默认是0.80（这个大小和阀值都是可以在配置文件里进行配置的），同时map还会为输出操作启动一个守护线程，如果缓冲区的内存达到了阀值的80%时候，这个守护线程就会把内容写到磁盘上，这个过程叫spill，另外的20%内存可以继续写入要写进磁盘的数据，写入磁盘和写入内存操作是互不干扰的，如果缓存区被撑满了，那么map就会阻塞写入内存的操作，让写入磁盘操作完成后再继续执行写入内存操作，前面我讲到写入磁盘前会有个排序操作，这个是在写入磁盘操作时候进行，不是在写入内存时候进行的，如果我们定义了combiner函数，那么排序前还会执行combiner操作。<br> 每次spill操作也就是写入磁盘操作时候就会写一个溢出文件，也就是说在做map输出有几次spill就会产生多少个溢出文件，等map输出全部做完后，map会合并这些输出文件。这个过程里还会有一个Partitioner操作，对于这个操作很多人都很迷糊，其实Partitioner操作和map阶段的输入分片（Input split）很像，一个Partitioner对应一个reduce作业，如果我们mapreduce操作只有一个reduce操作，那么Partitioner就只有一个，如果我们有多个reduce操作，那么Partitioner对应的就会有多个，Partitioner因此就是reduce的输入分片，这个程序员可以编程控制，主要是根据实际key和value的值，根据实际业务类型或者为了更好的reduce负载均衡要求进行，这是提高reduce效率的一个关键所在。到了reduce阶段就是合并map输出文件了，Partitioner会找到对应的map输出文件，然后进行复制操作，复制操作时reduce会开启几个复制线程，这些线程默认个数是5个，程序员也可以在配置文件更改复制线程的个数，这个复制过程和map写入磁盘过程类似，也有阀值和内存大小，阀值一样可以在配置文件里配置，而内存大小是直接使用reduce的tasktracker的内存大小，复制时候reduce还会进行排序操作和合并文件操作，这些操作完了就会进行reduce计算了。</li>
<li>reduce阶段：和map函数一样也是程序员编写的，最终结果是存储在hdfs上的。<h4 id="Mapreduce_u7684_u76F8_u5173_u95EE_u9898"><a href="#Mapreduce_u7684_u76F8_u5173_u95EE_u9898" class="headerlink" title="Mapreduce的相关问题"></a>Mapreduce的相关问题</h4>这里我要谈谈我学习mapreduce思考的一些问题，都是我自己想出解释的问题，但是某些问题到底对不对，就要广大童鞋帮我确认了。<br>（1）jobtracker的单点故障：jobtracker和hdfs的namenode一样也存在单点故障，单点故障一直是hadoop被人诟病的大问题，为什么hadoop的做的文件系统和mapreduce计算框架都是高容错的，但是最重要的管理节点的故障机制却如此不好，我认为主要是namenode和jobtracker在实际运行中都是在内存操作，而做到内存的容错就比较复杂了，只有当内存数据被持久化后容错才好做，namenode和jobtracker都可以备份自己持久化的文件，但是这个持久化都会有延迟，因此真的出故障，任然不能整体恢复，另外hadoop框架里包含zookeeper框架，zookeeper可以结合jobtracker，用几台机器同时部署jobtracker，保证一台出故障，有一台马上能补充上，不过这种方式也没法恢复正在跑的mapreduce任务。<br>（2）做mapreduce计算时候，输出一般是一个文件夹，而且该文件夹是不能存在，我在出面试题时候提到了这个问题，而且这个检查做的很早，当我们提交job时候就会进行，mapreduce之所以这么设计是保证数据可靠性，如果输出目录存在reduce就搞不清楚你到底是要追加还是覆盖，不管是追加和覆盖操作都会有可能导致最终结果出问题，mapreduce是做海量数据计算，一个生产计算的成本很高，例如一个job完全执行完可能要几个小时，因此一切影响错误的情况mapreduce是零容忍的。<br>（3） Mapreduce还有一个InputFormat和OutputFormat，我们在编写map函数时候发现map方法的参数是之间操作行数据，没有牵涉到InputFormat，这些事情在我们new Path时候mapreduce计算框架帮我们做好了，而OutputFormat也是reduce帮我们做好了，我们使用什么样的输入文件，就要调用什么样的InputFormat，InputFormat是和我们输入的文件类型相关的，mapreduce里常用的InputFormat有FileInputFormat普通文本文件，SequenceFileInputFormat是指hadoop的序列化文件，另外还有KeyValueTextInputFormat。OutputFormat就是我们想最终存储到hdfs系统上的文件格式了，这个根据你需要定义了，hadoop有支持很多文件格式，这里不一一列举，想知道百度下就看到了。</li>
</ol>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-MapReduce实例浅析" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/10/02/MapReduce实例浅析/" class="article-date">
  	<time datetime="2015-10-02T07:23:12.000Z" itemprop="datePublished">2015-10-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/10/02/MapReduce实例浅析/">MapReduce实例浅析</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="MapReduce_u5B9E_u4F8B_u6D45_u6790"><a href="#MapReduce_u5B9E_u4F8B_u6D45_u6790" class="headerlink" title="MapReduce实例浅析"></a>MapReduce实例浅析</h2><h4 id="1-MapReduce_u6982_u8FF0"><a href="#1-MapReduce_u6982_u8FF0" class="headerlink" title="1.MapReduce概述"></a>1.MapReduce概述</h4><blockquote>
<p>Hadoop Map/Reduce是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集。<br>    一个Map/Reduce 作业（job） 通常会把输入的数据集切分为若干独立的数据块，由 map任务（task）以完全并行的方式处理它们。框架会对map的输出先进行排序， 然后把结果输入给reduce任务。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。<br>    通常，Map/Reduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点通常在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。<br>    Map/Reduce框架由一个单独的master JobTracker 和每个集群节点一个slave TaskTracker共同组成。master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上，master监控它们的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务。<br>    应用程序至少应该指明输入/输出的位置（路径），并通过实现合适的接口或抽象类提供map和reduce函数。再加上其他作业的参数，就构成了作业配置（job configuration）。然后，Hadoop的 job client提交作业（jar包/可执行程序等）和配置信息给JobTracker，后者负责分发这些软件和配置信息给slave、调度任务并监控它们的执行，同时提供状态和诊断信息给job-client。<br>虽然Hadoop框架是用Java实现的，但Map/Reduce应用程序则不一定要用 Java来写 。<br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Shili1.jpg" alt="MapReduce处理大数据过程"></p>
</blockquote>
<h4 id="2-_u6837_u4F8B_u5206_u6790_uFF1A_u5355_u8BCD_u8BA1_u6570"><a href="#2-_u6837_u4F8B_u5206_u6790_uFF1A_u5355_u8BCD_u8BA1_u6570" class="headerlink" title="2.样例分析：单词计数"></a>2.样例分析：单词计数</h4><blockquote>
<h5 id="WordCount_u6E90_u7801_u5206_u6790"><a href="#WordCount_u6E90_u7801_u5206_u6790" class="headerlink" title="WordCount源码分析"></a>WordCount源码分析</h5><p>单词计数是最简单也是最能体现MapReduce思想的程序之一，该程序完整的代码可以在Hadoop安装包的src/examples目录下找到<br>单词计数主要完成的功能是：统计一系列文本文件中每个单词出现的次数，如图所示：<br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce%26%26Shili2.jpg" alt="单词计数"><br>（1）    Map过程<br>Map过程需要继承org.apache.hadoop.mapreduce包中的Mapper类，并重写map方法<br>通过在map方法中添加两句把key值和value值输出到控制台的代码，可以发现map方法中的value值存储的是文本文件中的一行（以回车符作为行结束标记），而key值为该行的首字符相对于文本文件的首地址的偏移量。然后StringTokenizer类将每一行拆分成一个个的单词，并将<word,1>作为map方法的结果输出，其余的工作都交由MapReduce框架处理。其中IntWritable和Text类是Hadoop对int和string类的封装，这些类能够被串行化，以方便在分布式环境中进行数据交换。</word,1></p>
<p>TokenizerMapper的实现代码如下：</p>
</blockquote>
<pre><code>public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
    System.out.println(&quot;key = &quot; + key.toString());
    //添加查看key值
    System.out.println(&quot;value = &quot; + value.toString());
    //添加查看value值
    StringTokenizer itr = new StringTokenizer(value.toString());
        while (itr.hasMoreTokens()) {
            word.set(itr.nextToken());
            context.write(word, one);
        }
    }
}
</code></pre><p>（2）    Reduce过程</p>
<blockquote>
<p>Reduce过程需要继承org.apache.hadoop.mapreduce包中的Reducer类，并重写reduce方法<br>reduce方法的输入参数key为单个单词，而values是由各Mapper上对应单词的计数值所组成的列表，所以只要遍历values并求和，即可得到某个单词的出现总次数<br>IntSumReduce类的实现代码如下：</p>
</blockquote>
<pre><code>public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
    System.out.println(&quot;key = &quot; + key.toString());
    //添加查看key值
    System.out.println(&quot;value = &quot; + value.toString());
    //添加查看value值
    StringTokenizer itr = new StringTokenizer(value.toString());
    while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
    }
}
</code></pre><p>}</p>
<p>（3）    执行MapReduce任务</p>
<blockquote>
<p>在MapReduce中，由Job对象负责管理和运行一个计算任务，并通过Job的一些方法对任务的参数进行相关的设置。此处设置了使用TokenizerMapper完成Map过程和使用的IntSumReduce完成Combine和Reduce过程。还设置了Map过程和Reduce过程的输出类型：key的类型为Text，value的类型为IntWritable。任务的输入和输出路径则由命令行参数指定，并由FileInputFormat和FileOutputFormat分别设定。完成相应任务的参数设定后，即可调用job.waitForCompletion()方法执行任务，主函数实现如下：</p>
</blockquote>
<pre><code>public static void main(String[] args) throws Exception {
Configuration conf = new Configuration();
String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
if (otherArgs.length != 2) {
  System.err.println(&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;);
  System.exit(2);
}
Job job = new Job(conf, &quot;word count&quot;);
job.setJarByClass(wordCount.class);
job.setMapperClass(TokenizerMapper.class);
job.setCombinerClass(IntSumReducer.class);
job.setReducerClass(IntSumReducer.class);
job.setOutputKeyClass(Text.class);
job.setOutputValueClass(IntWritable.class);
FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
System.exit(job.waitForCompletion(true) ? 0 : 1);
}
}
</code></pre><h5 id="WordCount_u5904_u7406_u8FC7_u7A0B"><a href="#WordCount_u5904_u7406_u8FC7_u7A0B" class="headerlink" title="WordCount处理过程"></a>WordCount处理过程</h5><blockquote>
<p>上面给出了WordCount的设计思路和源码，但是没有深入细节，下面对WordCount进行更加详细的分析：<br>1.将文件拆分成splits，由于测试用的文件较小，所以每一个文件为一个split，并将文件按行分割成<key, value="">对，如图，这一步由Mapreduce框架自动完成，其中偏移量包括了回车所占的字符<br>2.将分割好的<key, value="">对交给用户定义的map方法进行处理，生成新的<key, value="">对<br>3.得到map方法输出的<key, value="">对后，Mapper会将它们按照key值进行排序，并执行Combine过程，将key值相同的value值累加，得到Mapper的最终输出结果，如图：<br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Shili3.jpg" alt="Reduce过程"><br>4.Reduce先对从Mapper接收的数据进行排序，再交由用户自定义的reduce方法进行处理，得到新的<key, value="">对，并作为WordCount的输出结果，如图：<br><img src="http://7xract.com1.z0.glb.clouddn.com/MapReduce&amp;&amp;Shili4.jpg" alt="Reduce输出结果"></key,></key,></key,></key,></key,></p>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-TCP窗口滑动以及拥塞控制" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/03/01/TCP窗口滑动以及拥塞控制/" class="article-date">
  	<time datetime="2015-03-01T02:13:21.000Z" itemprop="datePublished">2015-03-01</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/03/01/TCP窗口滑动以及拥塞控制/">TCP窗口滑动以及拥塞控制</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="TCP_u7A97_u53E3_u6ED1_u52A8_u4EE5_u53CA_u62E5_u585E_u63A7_u5236"><a href="#TCP_u7A97_u53E3_u6ED1_u52A8_u4EE5_u53CA_u62E5_u585E_u63A7_u5236" class="headerlink" title="TCP窗口滑动以及拥塞控制"></a>TCP窗口滑动以及拥塞控制</h2><p>TCP协议作为一个可靠的面向流的传输协议，其可靠性和流量控制由滑动窗口协议保证，而拥塞控制则由控制窗口结合一系列的控制算法实现。</p>
<blockquote>
<p>一、滑动窗口协议<br>     关于这部分自己不晓得怎么叙述才好，因为理解的部分更多，下面就用自己的理解来介绍下TCP的精髓：滑动窗口协议。<br>     所谓滑动窗口协议，自己理解有两点：1. “窗口”对应的是一段可以被发送者发送的字节序列，其连续的范围称之为“窗口”；2. “滑动”则是指这段“允许发送的范围”是可以随着发送的过程而变化的，方式就是按顺序“滑动”。在引入一个例子来说这个协议之前，我觉得很有必要先了解以下前提：<br>1）TCP协议的两端分别为发送者A和接收者B，由于是全双工协议，因此A和B应该分别维护着一个独立的发送缓冲区和接收缓冲区，由于对等性（A发B收和B发A收），我们以A发送B接收的情况作为例子；<br>2）发送窗口是发送缓存中的一部分，是可以被TCP协议发送的那部分，其实应用层需要发送的所有数据都被放进了发送者的发送缓冲区；<br>3）发送窗口中相关的有四个概念：已发送并收到确认的数据（不再发送窗口和发送缓冲区之内）、已发送但未收到确认的数据（位于发送窗口之中）、允许发送但尚未发送的数据以及发送窗口外发送缓冲区内暂时不允许发送的数据；<br>4）每次成功发送数据之后，发送窗口就会在发送缓冲区中按顺序移动，将新的数据包含到窗口中准备发送；<br>     TCP建立连接的初始，B会告诉A自己的接收窗口大小，比如为‘20’：<br>     字节31-50为发送窗口<br><img src="http://7xract.com1.z0.glb.clouddn.com/TCP%E7%AA%97%E5%8F%A3%E6%BB%91%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6_1.png" alt="TCP窗口滑动以及拥塞控制_1"><br>A发送11个字节后，发送窗口位置不变，B接收到了乱序的数据分组：<br><img src="http://7xract.com1.z0.glb.clouddn.com/TCP%E7%AA%97%E5%8F%A3%E6%BB%91%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6_2.png" alt="TCP窗口滑动以及拥塞控制_2"><br>只有当A成功发送了数据，即发送的数据得到了B的确认之后，才会移动滑动窗口离开已发送的数据；同时B则确认连续的数据分组，对于乱序的分组则先接收下来，避免网络重复传递：<br><img src="http://7xract.com1.z0.glb.clouddn.com/TCP%E7%AA%97%E5%8F%A3%E6%BB%91%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6_3.png" alt="TCP窗口滑动以及拥塞控制_3"></p>
</blockquote>
<hr>
<blockquote>
<p>二、流量控制<br>     流量控制方面主要有两个要点需要掌握。一是TCP利用滑动窗口实现流量控制的机制；二是如何考虑流量控制中的传输效率。</p>
<ol>
<li>流量控制<br>  所谓流量控制，主要是接收方传递信息给发送方，使其不要发送数据太快，是一种端到端的控制。主要的方式就是返回的ACK中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送：<br><img src="http://7xract.com1.z0.glb.clouddn.com/TCP%E7%AA%97%E5%8F%A3%E6%BB%91%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6_4.png" alt="TCP窗口滑动以及拥塞控制_4"><br>这里面涉及到一种情况，如果B已经告诉A自己的缓冲区已满，于是A停止发送数据；等待一段时间后，B的缓冲区出现了富余，于是给A发送报文告诉A我的rwnd大小为400，但是这个报文不幸丢失了，于是就出现A等待B的通知||B等待A发送数据的死锁状态。为了处理这种问题，TCP引入了持续计时器（Persistence timer），当A收到对方的零窗口通知时，就启用该计时器，时间到则发送一个1字节的探测报文，对方会在此时回应自身的接收窗口大小，如果结果仍未0，则重设持续计时器，继续等待。</li>
<li>传递效率<br>  一个显而易见的问题是：单个发送字节单个确认，和窗口有一个空余即通知发送方发送一个字节，无疑增加了网络中的许多不必要的报文（请想想为了一个字节数据而添加的40字节头部吧！），所以我们的原则是尽可能一次多发送几个字节，或者窗口空余较多的时候通知发送方一次发送多个字节。对于前者我们广泛使用Nagle算法，即：<br>1） 若发送应用进程要把发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，把后面的字节先缓存起来；<br>2）当发送方收到第一个字节的确认后（也得到了网络情况和对方的接收窗口大小），再把缓冲区的剩余字节组成合适大小的报文发送出去；<br>3） 当到达的数据已达到发送窗口大小的一半或以达到报文段的最大长度时，就立即发送一个报文段；<br>  对于后者我们往往的做法是让接收方等待一段时间，或者接收方获得足够的空间容纳一个报文段或者等到接受缓存有一半空闲的时候，再通知发送方发送数据。</li>
</ol>
</blockquote>
<hr>
<blockquote>
<p>三、拥塞控制<br>     网络中的链路容量和交换结点中的缓存和处理机都有着工作的极限，当网络的需求超过它们的工作极限时，就出现了拥塞。拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。常用的方法就是：</p>
<ol>
<li>慢开始、拥塞控制</li>
<li>快重传、快恢复<br>  一切的基础还是慢开始，这种方法的思路是这样的：<br>1） 发送方维持一个叫做“拥塞窗口”的变量，该变量和接收端口共同决定了发送者的发送窗口；<br>2） 当主机开始发送数据时，避免一下子将大量字节注入到网络，造成或者增加拥塞，选择发送一个1字节的试探报文；<br>3）当收到第一个字节的数据的确认后，就发送2个字节的报文；<br>4） 若再次收到2个字节的确认，则发送4个字节，依次递增2的指数级；<br>5）最后会达到一个提前预设的“慢开始门限”，比如24，即一次发送了24个分组，此时遵循下面的条件判定：<br>cwnd &lt; ssthresh， 继续使用慢开始算法；<br>cwnd &gt; ssthresh，停止使用慢开始算法，改用拥塞避免算法；<br>cwnd = ssthresh，既可以使用慢开始算法，也可以使用拥塞避免算法；<br>6） 所谓拥塞避免算法就是：每经过一个往返时间RTT就把发送方的拥塞窗口+1，即让拥塞窗口缓慢地增大，按照线性规律增长；<br>7）当出现网络拥塞，比如丢包时，将慢开始门限设为原先的一半，然后将cwnd设为1，执行慢开始算法（较低的起点，指数级增长）；<br><img src="http://7xract.com1.z0.glb.clouddn.com/TCP%E7%AA%97%E5%8F%A3%E6%BB%91%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6_5.png" alt="TCP窗口滑动以及拥塞控制_5"><br>上述方法的目的是在拥塞发生时循序减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够的时间把队列中积压的分组处理完毕。慢开始和拥塞控制算法常常作为一个整体使用，而快重传和快恢复则是为了减少因为拥塞导致的数据包丢失带来的重传时间，从而避免传递无用的数据到网络。快重传的机制是：<br>1） 接收方建立这样的机制，如果一个包丢失，则对后续的包继续发送针对该包的重传请求；<br>2） 一旦发送方接收到三个一样的确认，就知道该包之后出现了错误，立刻重传该包；<br>3）此时发送方开始执行“快恢复”算法：<br>慢开始门限减半；<br>cwnd设为慢开始门限减半后的数值；<br>执行拥塞避免算法（高起点，线性增长）；<br><img src="http://7xract.com1.z0.glb.clouddn.com/TCP%E7%AA%97%E5%8F%A3%E6%BB%91%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6_6.png" alt="TCP窗口滑动以及拥塞控制_6"></li>
</ol>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/network/">network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Network/">Network</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-VLAN" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/02/20/VLAN/" class="article-date">
  	<time datetime="2015-02-20T02:13:09.000Z" itemprop="datePublished">2015-02-20</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/02/20/VLAN/">VLAN</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="VLAN"><a href="#VLAN" class="headerlink" title="VLAN"></a>VLAN</h2><blockquote>
<p>概念：VLAN（Virtual Local Area Network）<br>作用：隔离业务；分割广播域<br>默认情况下，交换机自带VLAN1，所有的端口都属于VLAN1。<br><img src="http://7xract.com1.z0.glb.clouddn.com/3_VLAN1.png" alt="VLAN隔离业务"><br>如：192.168.10.0/24 192.168.20.0/24<br><img src="http://7xract.com1.z0.glb.clouddn.com/3_VLAN2.png" alt="VLAN分割广播域"><br><img src="http://7xract.com1.z0.glb.clouddn.com/3_VLAN3.png" alt="Dot1Q以太网帧格式"><br>VLAN的区分：<br>    在源地址和长度/类型字节之间插入长度为4字节的802.1Q帧头。<br><img src="http://7xract.com1.z0.glb.clouddn.com/3_VLAN4.png" alt="Dot1Q帧抓包"><br><img src="http://7xract.com1.z0.glb.clouddn.com/3_VLAN5.png" alt="相同VLAN可以互访"><br><a href="http://edu.51cto.com/lesson/id-20980.html" target="_blank" rel="external">“VLAN”视频播放地址</a></p>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/network/">network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Network/">Network</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Route" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/02/19/Route/" class="article-date">
  	<time datetime="2015-02-19T13:05:19.000Z" itemprop="datePublished">2015-02-19</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/02/19/Route/">路由器工作原理及数据流分析</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="u8DEF_u7531_u5668_u5DE5_u4F5C_u539F_u7406_u53CA_u6570_u636E_u6D41_u5206_u6790"><a href="#u8DEF_u7531_u5668_u5DE5_u4F5C_u539F_u7406_u53CA_u6570_u636E_u6D41_u5206_u6790" class="headerlink" title="路由器工作原理及数据流分析"></a>路由器工作原理及数据流分析</h2><blockquote>
<p><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route1.png" alt="路由器工作原理"><br>路由表：网段+掩码 出口<br>    源主机将目标主机的IP地址与自己的掩码进行“与”运算，同时将自己的IP地址也与自己掩码“与”，如相同，则在同一网段。<br>当同一网段时：通过ARP（Address Resolution Protocol）地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议，请求对方MAC，直接进行二层通信。<br>当不在同网段时，将数据包发送给默认网关，由网关进行三层转发。<br>“与”运算时用的是自己的掩码。如下图所示：<br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route2.png" alt="主机通信原理测试"></p>
</blockquote>
<hr>
<blockquote>
<p>三层转发过程：<br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route3.png" alt="三层转发过程"><br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route4.png" alt="步骤一"><br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route5.png" alt="步骤二"><br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route6.png" alt="步骤三"><br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route7.png" alt="步骤四"><br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route8.png" alt="步骤五"><br>TTL是 Time To Live的缩写，该字段指定IP包被路由器丢弃之前允许通过的最大网段数量。TTL是IPv4包头的一个8 bit字段。TTL的作用是限制IP数据包在计算机网络中的存在的时间。TTL的最大值是255，TTL的一个推荐值是64。虽然TTL从字面上翻译，是可以存活的时间，但实际上TTL是IP数据包在计算机网络中可以转发的最大跳数。TL字段由IP数据包的发送者设置，在IP数据包从源到目的的整个转发路径上，每经过一个路由器，路由器都会修改这个TTL字段值，具体的做法是把该TTL的值减1，然后再将IP包转发出去。如果在IP包到达目的IP之前，TTL减少为0，路由器将会丢弃收到的TTL=0的IP包并向IP包的发送者发送 ICMP time exceeded消息。<br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route9.png" alt="步骤六"></p>
</blockquote>
<hr>
<blockquote>
<p>电脑的ARP表：<br><img src="http://7xract.com1.z0.glb.clouddn.com/2_Route10.png" alt="电脑ARP表"><br>可以看到局域网内广播和组播的地址，以及联系过的电脑主机。<br><a href="http://edu.51cto.com/lesson/id-20964.html" target="_blank" rel="external">“路由器工作原理及数据流分析”视频播放地址</a></p>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/network/">network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Network/">Network</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Net&amp;&amp;Switsh" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/01/17/Net&&Switsh/" class="article-date">
  	<time datetime="2015-01-17T08:08:21.000Z" itemprop="datePublished">2015-01-17</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/17/Net&&Switsh/">网络三要素及交换机工作原理</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="u7F51_u7EDC_u4E09_u8981_u7D20_u53CA_u4EA4_u6362_u673A_u5DE5_u4F5C_u539F_u7406"><a href="#u7F51_u7EDC_u4E09_u8981_u7D20_u53CA_u4EA4_u6362_u673A_u5DE5_u4F5C_u539F_u7406" class="headerlink" title="网络三要素及交换机工作原理"></a>网络三要素及交换机工作原理</h2><blockquote>
<p><img src="http://7xract.com1.z0.glb.clouddn.com/1_Net%26%26Switsh1.png" alt="网络三要素"><br>网络三要素：终端、介质、网络设备<br>终端：电脑、手机等。<br>介质：网线、wifi、光纤等。<br>网络设备：路由器、交换机、防火墙、负载均衡设备等。</p>
</blockquote>
<ol>
<li><p>交换机工作原理</p>
<blockquote>
<p>HUB与Switch内部构造对比：<br><img src="http://7xract.com1.z0.glb.clouddn.com/1_Net%26%26Switsh2.png" alt="HUB与Switch内部构造对比"><br>外形相似，HUB利用总线发送数据，直接广播。采用CSMA/CD（Carrier Sense Multiple Access with Collision Detection）即带冲突检测的载波监听多路访问技术。CSMA/CD的工作原理是: 若信道空闲，发送数据。若忙碌，则等待信道数据传输结束后再发送数据；若冲突,则停止发送数据，等待再重新尝试。缺点：效率不高。交换机利用交换矩阵发送数据，根据mac地址发送数据。</p>
</blockquote>
</li>
<li><p>交换机的学习功能</p>
<blockquote>
<p><img src="http://7xract.com1.z0.glb.clouddn.com/1_Net%26%26Switsh1.png" alt="网络三要素"><br>开始交换机中的MAC地址为空。<br>如E0开始传输数据，则MAC地址表写入E0：0260.8C01.1111。即交换机对于收到的帧，学习其源MAC地址放入MAC地址表。<br>接着，交换机根据收到的帧中间的目的MAC地址，查找MAC地址表进行转发：<br>—　如果匹配，则从相应的端口转发出去（除FCS外，不做改动），只改变FCS。<br>侦校验和：<br>Frame Check Sequence:<br>这个字段包括4字节循环冗余校检码(CRC)用于检查错误.当一个原站组装一个 MAC帧，他在所有字节(从Destination MAC Address到Pad字段)执行一个CRC 计算，原站将计算的结果放入这个字段，并作为帧的一部分传输给目的站， 当帧被目的站接受后，目的站进行同样的校检，如果校检和同字段中的值不同，目的站将认为在传输中发生错误并丢弃这个帧.<br>—　如果没有匹配，则泛洪（flooding），除了源端口外向所有端口转发。此时，B、D发现MAC地址不匹配，丢弃数据帧。C接收数据帧，并回复A，交换机学习C的MAC地址。<br>广播帧：目的MAC地址：FFFF.FFFF.FFFF，传给LAN中所有设备。<br>组播帧：通常用于IP组播的以太网的组播地址以0100.5E或0100.5F开头，这些帧发送给LAN中的一组设备，而不是全部。<br><img src="http://7xract.com1.z0.glb.clouddn.com/1_Net%26%26Switsh4.png" alt="组播帧的处理"><br>交换机内部交换方式：<br>直接转发：交换机检测到目标MAC地址后即转发帧。（快，错误率较高）<br>存储转发：收到完整的帧并检查无错误后才转发。（最常用，慢，正确率高）<br>无碎片转发：交换机检测到帧的前64字节（实验得出）后即转发。（折中）<br><a href="http://edu.51cto.com/lesson/id-20656.html" target="_blank" rel="external">“网络三要素及交换机工作原理”视频播放地址</a></p>
</blockquote>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/network/">network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习笔记/">学习笔记</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Network/">Network</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Oylwhu Blog
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>